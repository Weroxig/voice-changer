--extra-index-url https://download.pytorch.org/whl/rocm6.0
# onnxruntime doesn't come with prebuilt binaries, so we use the ones that come with PyTorch
# torch >=2.4.0 is compiled with cuDNN 9.x
# onnxruntime-rocm is compiled with cuDNN 8.x
torch==2.3.1
torchaudio
faiss-cpu==1.8.0

onnxscript
onnxsim
onnxruntime-rocm @ https://repo.radeon.com/rocm/manylinux/rocm-rel-6.0.2/onnxruntime_rocm-inference-1.17.0-cp310-cp310-linux_x86_64.whl
torchcrepe
torchfcpe
safetensors
