# onnxruntime doesn't come with prebuilt binaries, so we use the ones that come with PyTorch
# Torch >=2.4.0 for CUDA 11.8 and 12.x is compiled with cuDNN 9.x
# onnxruntime-gpu for CUDA 12.x is compiled with CUDA 12.x and cuDNN 9.x
--extra-index-url https://download.pytorch.org/whl/cu121
--extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/
torch>=2.4.0
torchaudio
faiss-cpu==1.8.0; sys_platform!='linux'
faiss-gpu; sys_platform=='linux'

onnxscript
onnxsim
onnxruntime-gpu
torchcrepe
torchfcpe
safetensors
